"""
SmartChunker adaptatif - version avec support glossaire Excel.

Le glossaire Excel est trait√© en amont par DocumentLoader.load_glossary_xlsx().
SmartChunker est appel√© UNIQUEMENT sur les documents PDF Maroclear.

IMPORTANT : Les chunks produits par SmartChunker re√ßoivent type='narrative'
ou type='section', jamais type='glossaire' (r√©serv√© au glossaire Excel).
"""

from enum import Enum
from typing import List, Dict, Optional
import re


class DocumentFormat(Enum):
    GLOSSARY_NEWLINE = "glossary_newline"
    GLOSSARY_COLON   = "glossary_colon"
    GLOSSARY_INLINE  = "glossary_inline"
    NARRATIVE        = "narrative"
    SECTIONED        = "sectioned"


class SmartChunker:

    # =========================================================
    # D√âTECTION AUTOMATIQUE DU FORMAT
    # =========================================================

    def detect_format(self, text: str) -> DocumentFormat:
        sample = text[:5000]
        lines  = [l.strip() for l in sample.split("\n") if l.strip()]
        total  = len(lines)
        if total == 0:
            return DocumentFormat.NARRATIVE

        short_followed_by_long = 0
        colon_pattern          = 0
        section_markers        = 0
        inline_glued           = 0

        for i, line in enumerate(lines):
            if len(line) < 80 and i + 1 < total and len(lines[i + 1]) > 80:
                short_followed_by_long += 1
            if re.match(r'^[^:]{3,60}:\s+[A-Z√Ä-≈∏]', line):
                colon_pattern += 1
            if re.match(r'^(‚Ä∫|#{1,3}\s|[A-Z√Ä√Ç√â√à√ä√ã√é√è√î√ô√õ√ú√á\s]{6,}$)', line):
                section_markers += 1
            if re.search(r'[a-z√†-√ø]{3,}[A-Z√Ä-≈∏][a-z√†-√ø]', line):
                inline_glued += 1

        scores = {
            DocumentFormat.GLOSSARY_NEWLINE: short_followed_by_long / total,
            DocumentFormat.GLOSSARY_COLON:   colon_pattern          / total,
            DocumentFormat.GLOSSARY_INLINE:  inline_glued           / total,
            DocumentFormat.SECTIONED:        section_markers        / total,
        }

        print(f"  üìä Scores de d√©tection :")
        for fmt, score in sorted(scores.items(), key=lambda x: -x[1]):
            print(f"     {fmt.value:<22} {score:.3f}")

        best  = max(scores, key=scores.get)
        score = scores[best]

        # ‚îÄ‚îÄ Correction du faux positif GLOSSARY_INLINE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # INLINE score faussement ~1.0 sur TOUT texte fran√ßais (pattern trop large)
        # NEWLINE seuil √† 0.25 : un vrai glossaire a beaucoup de "terme court
        # suivi d'une d√©finition longue". Un narratif peut scorer 0.10-0.15
        # accidentellement via des sous-titres courts suivis de paragraphes.
        if best == DocumentFormat.GLOSSARY_INLINE:
            if scores[DocumentFormat.GLOSSARY_NEWLINE] >= 0.25:
                best = DocumentFormat.GLOSSARY_NEWLINE
                print("  ‚ö†Ô∏è  INLINE ‚Üí NEWLINE (signal newline fort, vrai glossaire)")
            elif scores[DocumentFormat.SECTIONED] >= 0.05:
                best = DocumentFormat.SECTIONED
                print("  ‚ö†Ô∏è  INLINE ‚Üí SECTIONED (marqueurs de sections d√©tect√©s)")
            elif score < 0.50:
                best = DocumentFormat.NARRATIVE
                print("  ‚ö†Ô∏è  INLINE ‚Üí NARRATIVE (score ambigu, d√©faut narratif)")

        if best in scores and scores[best] < 0.04:
            best = DocumentFormat.NARRATIVE

        print(f"  ‚úÖ Format retenu : {best.value}\n")
        return best

    # =========================================================
    # POINT D'ENTR√âE UNIQUE
    # =========================================================

    def chunk(
        self,
        text: str,
        source: str = "unknown",
        force_format: Optional[DocumentFormat] = None,
        chunk_size: int = 600,
        overlap: int = 80,
    ) -> List[Dict]:
        fmt = force_format or self.detect_format(text)

        dispatch = {
            DocumentFormat.GLOSSARY_NEWLINE: self._chunk_glossary_newline,
            DocumentFormat.GLOSSARY_COLON:   self._chunk_glossary_colon,
            DocumentFormat.GLOSSARY_INLINE:  self._chunk_glossary_inline,
            DocumentFormat.SECTIONED:        lambda t: self._chunk_sectioned(t, chunk_size),
            DocumentFormat.NARRATIVE:        lambda t: self._chunk_narrative(t, chunk_size, overlap),
        }

        chunks = dispatch[fmt](text)

        for chunk in chunks:
            chunk["metadata"]["source"] = source
            chunk["metadata"]["format"] = fmt.value
            # ‚úÖ CORRECTION CLEF : √©craser le type pour ne jamais avoir
            # 'glossaire' sur un chunk PDF ‚Äî r√©serv√© au glossaire Excel
            if chunk["metadata"].get("type") == "glossaire":
                chunk["metadata"]["type"] = "narrative"

        return chunks

    # =========================================================
    # STRAT√âGIES
    # =========================================================

    def _chunk_glossary_newline(self, text: str) -> List[Dict]:
        lines = [l.strip() for l in text.split("\n")]
        chunks, current_term, current_def = [], None, []
        for line in lines:
            if not line:
                continue
            if self._is_term_line(line):
                if current_term and current_def:
                    chunks.append(self._make_glossary_chunk(current_term, current_def))
                current_term = line
                current_def  = []
            else:
                current_def.append(line)
        if current_term and current_def:
            chunks.append(self._make_glossary_chunk(current_term, current_def))
        return chunks

    def _chunk_glossary_colon(self, text: str) -> List[Dict]:
        chunks = []
        for line in text.split("\n"):
            line  = line.strip()
            match = re.match(r'^([^:]{3,60}):\s+(.+)', line)
            if match:
                chunks.append(self._make_glossary_chunk(match.group(1), [match.group(2)]))
        return chunks

    def _chunk_glossary_inline(self, text: str) -> List[Dict]:
        text = re.sub(
            r'([A-Z√Ä-≈∏a-z√†-√ø/\-()\''']{3,})([A-Z√Ä-≈∏][a-z√†-√ø])',
            lambda m: m.group(1) + "\n" + m.group(2),
            text
        )
        return self._chunk_glossary_newline(text)

    def _chunk_sectioned(self, text: str, chunk_size: int = 800) -> List[Dict]:
        pattern  = re.compile(
            r'(?m)(?=^(?:‚Ä∫\s+|\#{1,3}\s+|[A-Z√Ä√Ç√â√à√ä√ã√é√è√î√ô√õ√ú√á][A-Z√Ä√Ç√â√à√ä√ã√é√è√î√ô√õ√ú√á\s]{5,}$))'
        )
        sections = pattern.split(text)
        chunks   = []
        for section in sections:
            section = section.strip()
            if not section:
                continue
            if len(section) > chunk_size:
                for sub in self._narrative_raw(section, chunk_size):
                    chunks.append({"content": sub, "metadata": {"type": "narrative"}})
            else:
                chunks.append({"content": section, "metadata": {"type": "section"}})
        return chunks

    def _chunk_narrative(self, text: str, chunk_size: int = 600,
                         overlap: int = 80) -> List[Dict]:
        return [
            {"content": c, "metadata": {"type": "narrative"}}
            for c in self._narrative_raw(text, chunk_size, overlap)
        ]

    def _narrative_raw(self, text: str, chunk_size: int = 600,
                       overlap: int = 80) -> List[str]:
        """
        D√©coupe le texte en chunks par phrases avec overlap en MOTS.
        overlap=80 ‚Üí les 80 derniers mots du chunk pr√©c√©dent sont r√©p√©t√©s
        au d√©but du suivant, ce qui √©vite de couper les mots en plein milieu.
        """
        sentences = re.split(r'(?<=[.!?])\s+', text)
        chunks, current = [], ""

        for sentence in sentences:
            if len(current) + len(sentence) > chunk_size and current:
                chunks.append(current.strip())
                # Overlap en MOTS (pas en caract√®res) pour √©viter les coupures
                last_words  = current.split()
                overlap_words = last_words[-overlap:] if len(last_words) > overlap else last_words
                current = " ".join(overlap_words) + " " + sentence
            else:
                current += " " + sentence

        if current.strip():
            chunks.append(current.strip())
        return chunks

    # =========================================================
    # HELPERS
    # =========================================================

    def _is_term_line(self, line: str) -> bool:
        if not line or len(line) > 100:
            return False
        definition_starters = (
            "le ", "la ", "les ", "un ", "une ", "des ",
            "il ", "elle ", "on ", "ce ", "cette ", "ces ",
            "toute ", "tout ", "dans ", "lorsque ", "se dit",
            "correspond", "d√©signe ", "sont ", "permet ",
            "c'est ", "c ºest ", "en ", "par ", "pour ",
            "selon ", "dont ", "qui ", "que ", "l º", "l'",
        )
        lower = line.lower()
        if any(lower.startswith(s) for s in definition_starters):
            return False
        if line.endswith(".") and len(line) > 30:
            return False
        if "," in line and len(line) > 60:
            return False
        return True

    def _make_glossary_chunk(self, term: str, definition: List[str]) -> Dict:
        # type='narrative' et non 'glossaire' ‚Äî les chunks PDF ne sont pas
        # des entr√©es de glossaire m√™me si leur format ressemble √† un glossaire
        return {
            "content":  f"{term}\n{' '.join(definition)}",
            "metadata": {"term": term, "type": "narrative"},
        }