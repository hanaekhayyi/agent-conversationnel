"""
G√©n√©ration d'embeddings locaux avec nomic-embed-text via Ollama
"""

import ollama
from typing import List
import numpy as np


class LocalEmbeddings:
    """G√©n√®re des embeddings en local via Ollama (bge-m3)"""

    def __init__(self, model_name: str = "bge-m3"):
        self.model_name = model_name

        print(f"üîß Mod√®le d'embeddings : {model_name} (via Ollama)")

        # V√©rifier qu'Ollama est accessible et que le mod√®le est disponible
        try:
            available = [m["name"] for m in ollama.list()["models"]]
            if not any(self.model_name in m for m in available):
                print(
                    f"‚ö†Ô∏è  Mod√®le '{model_name}' introuvable. "
                    f"Lance : ollama pull {model_name}"
                )
            else:
                print(f"‚úÖ Mod√®le '{model_name}' disponible")
        except Exception as e:
            print(f"‚ö†Ô∏è  Impossible de contacter Ollama : {e}")

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------

    def _normalize(self, vector: List[float]) -> List[float]:
        """Normalise un vecteur (norme L2 = 1)."""
        arr = np.array(vector, dtype=np.float32)
        norm = np.linalg.norm(arr)
        if norm == 0:
            return vector
        return (arr / norm).tolist()

    def _embed_single(self, text: str) -> List[float]:
        """Appel brut √† l'API Ollama pour un texte."""
        response = ollama.embeddings(model=self.model_name, prompt=text)
        return response["embedding"]

    # ------------------------------------------------------------------
    # API publique (identique √† l'ancienne classe)
    # ------------------------------------------------------------------

    def embed_documents(
        self, texts: List[str], batch_size: int = 32
    ) -> List[List[float]]:
        """
        G√©n√®re des embeddings normalis√©s pour une liste de documents.

        Le pr√©fixe 'search_document:' am√©liore la qualit√© de r√©cup√©ration
        avec nomic-embed-text.
        """
        print(f"üîÑ G√©n√©ration d'embeddings pour {len(texts)} documents...")

        embeddings: List[List[float]] = []

        for i, text in enumerate(texts):
            prefixed = f"search_document: {text}"
            raw = self._embed_single(prefixed)
            embeddings.append(self._normalize(raw))

            if (i + 1) % 10 == 0 or (i + 1) == len(texts):
                print(f"   {i + 1}/{len(texts)} trait√©s", end="\r")

        print()  # saut de ligne apr√®s le \r

        # V√©rification de la normalisation
        first_norm = np.linalg.norm(embeddings[0])
        print(
            f"‚úÖ Embeddings normalis√©s "
            f"(norme du 1er vecteur : {first_norm:.4f} ‚âà 1.0)"
        )

        return embeddings

    def embed_query(self, query: str) -> List[float]:
        """
        G√©n√®re un embedding normalis√© pour une requ√™te utilisateur.

        Le pr√©fixe 'search_query:' est distinct de 'search_document:'
        afin d'optimiser la similarit√© asym√©trique.
        """
        prefixed = f"search_query: {query}"
        raw = self._embed_single(prefixed)
        return self._normalize(raw)